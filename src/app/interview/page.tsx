"use client";

import { useRouter, useSearchParams } from "next/navigation";
import { useState, useEffect, useRef, useCallback, Suspense } from "react";
import { Button } from "@/components/ui/button";
import { AudioRecorder, AudioPlayer, encodeAudioToBase64 } from "@/lib/audio";
import { generateInterviewPrompt } from "@/lib/prompts";
import { INTERVIEWER_STYLES } from "@/lib/config";
import type { InterviewSettings, Message } from "@/types";

function InterviewContent() {
  const router = useRouter();
  const searchParams = useSearchParams();

  const [settings, setSettings] = useState<InterviewSettings | null>(null);
  const [status, setStatus] = useState<"idle" | "connecting" | "active" | "ending">("idle");
  const [messages, setMessages] = useState<Message[]>([]);
  const [currentTranscript, setCurrentTranscript] = useState("");
  const [remainingTime, setRemainingTime] = useState(0);
  const [isRecording, setIsRecording] = useState(false);
  const [isAISpeaking, setIsAISpeaking] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [pendingUserMessageId, setPendingUserMessageId] = useState<string | null>(null);
  const [displayedText, setDisplayedText] = useState("");
  const [isTyping, setIsTyping] = useState(false);
  const fullTextRef = useRef("");

  const wsRef = useRef<WebSocket | null>(null);
  const recorderRef = useRef<AudioRecorder | null>(null);
  const playerRef = useRef<AudioPlayer | null>(null);
  const timerRef = useRef<NodeJS.Timeout | null>(null);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const remainingTimeRef = useRef<number>(0); // ç”¨äºåœ¨å›è°ƒä¸­è®¿é—®å‰©ä½™æ—¶é—´
  const startRecordingRef = useRef<() => void>(() => {}); // ç”¨äºåœ¨æ¶ˆæ¯å¤„ç†ä¸­è°ƒç”¨

  // è§£æè®¾ç½®
  useEffect(() => {
    const settingsParam = searchParams.get("settings");
    if (settingsParam) {
      try {
        const parsed = JSON.parse(decodeURIComponent(settingsParam));
        setSettings(parsed);
        setRemainingTime(parsed.duration * 60);
      } catch {
        setError("æ— æ•ˆçš„é¢è¯•è®¾ç½®");
      }
    }
  }, [searchParams]);

  // æ»šåŠ¨åˆ°æœ€æ–°æ¶ˆæ¯
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  }, [messages, currentTranscript]);

  // åŒæ­¥ remainingTime åˆ° ref
  useEffect(() => {
    remainingTimeRef.current = remainingTime;
  }, [remainingTime]);

  // å€’è®¡æ—¶
  useEffect(() => {
    if (status === "active" && remainingTime > 0) {
      timerRef.current = setInterval(() => {
        setRemainingTime((prev) => {
          if (prev <= 1) {
            endInterview();
            return 0;
          }
          return prev - 1;
        });
      }, 1000);
    }

    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
    };
  }, [status]);

  // æ ¼å¼åŒ–æ—¶é—´
  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, "0")}:${secs.toString().padStart(2, "0")}`;
  };

  // æ‰‹åŠ¨å¼€å§‹å½•éŸ³
  const startRecording = useCallback(async () => {
    if (isRecording || !wsRef.current || isAISpeaking) {
      console.log("[å½•éŸ³] æ— æ³•å¼€å§‹å½•éŸ³:", { isRecording, isAISpeaking, hasWs: !!wsRef.current });
      return;
    }

    console.log("[å½•éŸ³] å¼€å§‹å½•éŸ³...");

    try {
      const recorder = new AudioRecorder();
      recorderRef.current = recorder;

      await recorder.start((audioData) => {
        if (wsRef.current?.readyState === WebSocket.OPEN) {
          const base64Audio = encodeAudioToBase64(audioData);
          wsRef.current.send(
            JSON.stringify({
              type: "input_audio_buffer.append",
              audio: base64Audio,
            })
          );
          // ä¸è¦æ¯å¸§éƒ½æ‰“å°ï¼Œå¤ªå¤šäº†
        }
      });

      setIsRecording(true);
      console.log("[å½•éŸ³] å½•éŸ³å·²å¼€å§‹");
    } catch (err) {
      console.error("[å½•éŸ³] å¯åŠ¨å¤±è´¥:", err);
      setError("æ— æ³•å¯åŠ¨éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™");
    }
  }, [isRecording, isAISpeaking]);

  // åŒæ­¥ startRecording åˆ° refï¼Œä»¥ä¾¿åœ¨æ¶ˆæ¯å¤„ç†ä¸­è°ƒç”¨
  useEffect(() => {
    startRecordingRef.current = startRecording;
  }, [startRecording]);

  // æ‰‹åŠ¨åœæ­¢å½•éŸ³å¹¶æäº¤
  const stopRecording = useCallback(() => {
    if (!isRecording || !wsRef.current) return;

    console.log("[å½•éŸ³] åœæ­¢å½•éŸ³å¹¶æäº¤");

    // åœæ­¢å½•éŸ³
    if (recorderRef.current) {
      recorderRef.current.stop();
      recorderRef.current = null;
    }
    setIsRecording(false);

    // ç«‹å³æ·»åŠ ç”¨æˆ·æ¶ˆæ¯å ä½ç¬¦ï¼Œç¡®ä¿æ¶ˆæ¯é¡ºåºæ­£ç¡®
    const messageId = Date.now().toString();
    const placeholderMessage: Message = {
      id: messageId,
      role: "user",
      content: "...",
      timestamp: Date.now(),
    };
    setMessages((prev) => [...prev, placeholderMessage]);
    setPendingUserMessageId(messageId);

    // æäº¤éŸ³é¢‘ç¼“å†²åŒº
    const commitMsg = { type: "input_audio_buffer.commit" };
    console.log("[å‘é€]", commitMsg);
    wsRef.current.send(JSON.stringify(commitMsg));

    // è®¡ç®—å‰©ä½™æ—¶é—´ä¿¡æ¯
    const mins = Math.floor(remainingTimeRef.current / 60);
    const secs = remainingTimeRef.current % 60;
    const timeInfo = `[ç³»ç»Ÿæç¤ºï¼šé¢è¯•å‰©ä½™æ—¶é—´ ${mins}åˆ†${secs}ç§’ï¼Œè¯·æ ¹æ®æ—¶é—´è°ƒæ•´é—®é¢˜æ·±åº¦å’Œæ•°é‡]`;

    // è§¦å‘ AI å›å¤ï¼Œé™„å¸¦æ—¶é—´ä¿¡æ¯
    const responseMsg = {
      type: "response.create",
      response: {
        modalities: ["audio", "text"],
        instructions: timeInfo, // å‘Šè¯‰AIå½“å‰å‰©ä½™æ—¶é—´
      },
    };
    console.log("[å‘é€]", responseMsg);
    wsRef.current.send(JSON.stringify(responseMsg));
  }, [isRecording]);

  // è¿æ¥ WebSocket
  const connectWebSocket = useCallback(async () => {
    if (!settings) return;

    setStatus("connecting");
    setError(null);

    try {
      // åˆå§‹åŒ–éŸ³é¢‘æ’­æ”¾å™¨
      playerRef.current = new AudioPlayer();

      // è¿æ¥ WebSocket ä»£ç†
      const wsUrl = process.env.NEXT_PUBLIC_WS_PROXY_URL || "ws://localhost:8768";
      const ws = new WebSocket(wsUrl);
      wsRef.current = ws;

      ws.onopen = () => {
        console.log("[WebSocket] å·²è¿æ¥");

        // å‘é€ session.update
        const prompt = generateInterviewPrompt({
          mode: settings.mode,
          position: settings.position,
          company: settings.company,
          round: settings.round as any,
          category: settings.category,
          techStack: (settings as any).techStack,
          resumeContent: settings.resumeContent,
          duration: settings.duration,
        });

        const voice = settings.round
          ? INTERVIEWER_STYLES[settings.round]?.voice || "ash"
          : "ash";

        const sessionUpdate = {
          type: "session.update",
          session: {
            modalities: ["audio", "text"],
            instructions: prompt,
            voice: voice,
            input_audio_format: "pcm16",
            output_audio_format: "pcm16",
            input_audio_transcription: { model: "whisper-1" },
            turn_detection: null, // æ‰‹åŠ¨æ¨¡å¼ï¼Œä¸ä½¿ç”¨è‡ªåŠ¨è¯­éŸ³æ£€æµ‹
          },
        };

        console.log("[å‘é€] session.update", { voice, promptLength: prompt.length });
        console.log("[System Prompt]", prompt);
        ws.send(JSON.stringify(sessionUpdate));

        // è§¦å‘ AI å¼€åœºç™½
        setTimeout(() => {
          const responseCreate = {
            type: "response.create",
            response: {
              modalities: ["audio", "text"],
            },
          };
          console.log("[å‘é€]", responseCreate);
          ws.send(JSON.stringify(responseCreate));
        }, 500);

        setStatus("active");
      };

      ws.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data);
          handleServerMessage(data);
        } catch (e) {
          console.error("Failed to parse message:", e);
        }
      };

      ws.onerror = (event) => {
        console.error("WebSocket error:", event);
        setError("è¿æ¥å‡ºé”™ï¼Œè¯·åˆ·æ–°é‡è¯•");
        setStatus("idle");
      };

      ws.onclose = () => {
        console.log("WebSocket closed");
        if (status === "active") {
          setStatus("ending");
        }
      };
    } catch (err) {
      console.error("Connection failed:", err);
      setError("è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ");
      setStatus("idle");
    }
  }, [settings]);

  // å¤„ç†æœåŠ¡å™¨æ¶ˆæ¯
  const handleServerMessage = (data: any) => {
    // è¯¦ç»†æ—¥å¿— - é™¤äº†éŸ³é¢‘æ•°æ®å¤–éƒ½æ‰“å°
    if (data.type !== "response.audio.delta" && data.type !== "input_audio_buffer.speech_started" && data.type !== "input_audio_buffer.speech_stopped") {
      console.log("[æ”¶åˆ°]", data.type, data);
    }

    switch (data.type) {
      case "session.created":
        console.log("[ä¼šè¯] å·²åˆ›å»º", data.session?.id);
        break;

      case "session.updated":
        console.log("[ä¼šè¯] å·²æ›´æ–°");
        break;

      case "response.audio.delta":
        // AI æ­£åœ¨è¯´è¯ - ä¸æ‰“å°æ¯å¸§
        setIsAISpeaking(true);
        if (data.delta && playerRef.current) {
          playerRef.current.play(data.delta);
        }
        break;

      case "response.audio_transcript.delta":
        // ç¼“å­˜æ–‡æœ¬ï¼Œä¸ç›´æ¥æ˜¾ç¤º
        fullTextRef.current += (data.delta || "");
        break;

      case "response.audio_transcript.done":
        // AI è¯´å®Œä¸€å¥è¯ï¼Œå¼€å§‹æµç•…æ‰“å­—æ•ˆæœ
        console.log("[AIè¯´å®Œ]", data.transcript);
        if (data.transcript) {
          setIsTyping(true);
          setDisplayedText("");
          setCurrentTranscript("");
          const text = data.transcript;
          let index = 0;

          const typeInterval = setInterval(() => {
            if (index < text.length) {
              const charsToAdd = Math.min(3, text.length - index);
              setDisplayedText(text.slice(0, index + charsToAdd));
              index += charsToAdd;
            } else {
              clearInterval(typeInterval);
              setIsTyping(false);
              const newMessage: Message = {
                id: Date.now().toString(),
                role: "assistant",
                content: text,
                timestamp: Date.now(),
              };
              setMessages((prev) => [...prev, newMessage]);
              setDisplayedText("");
            }
          }, 30);

          fullTextRef.current = "";
        }
        break;

      case "response.done":
        // AI å®Œå…¨è¯´å®Œï¼Œè‡ªåŠ¨å¼€å§‹å½•éŸ³
        console.log("[AIå›å¤å®Œæˆ] è‡ªåŠ¨å¼€å§‹å½•éŸ³...");
        setIsAISpeaking(false);
        // å»¶è¿Ÿä¸€ç‚¹å¼€å§‹å½•éŸ³ï¼Œç¡®ä¿çŠ¶æ€å·²æ›´æ–°
        setTimeout(() => {
          startRecordingRef.current();
        }, 300);
        break;

      case "conversation.item.input_audio_transcription.completed":
        // ç”¨æˆ·è¯­éŸ³è½¬å½•å®Œæˆï¼Œæ›´æ–°å ä½æ¶ˆæ¯
        console.log("[ç”¨æˆ·è¯´å®Œ]", data.transcript);
        if (data.transcript) {
          setMessages((prev) => {
            const updated = prev.map((msg) => {
              if (msg.id === pendingUserMessageId || (msg.role === "user" && msg.content === "...")) {
                return { ...msg, content: data.transcript };
              }
              return msg;
            });
            return updated;
          });
          setPendingUserMessageId(null);
        }
        break;

      case "rate_limits.updated":
        console.log("[è´¹ç‡é™åˆ¶]", data.rate_limits);
        break;

      case "response.created":
        console.log("[AIå¼€å§‹ç”Ÿæˆå›å¤]");
        break;

      case "response.output_item.added":
        console.log("[AIè¾“å‡ºé¡¹æ·»åŠ ]");
        break;

      case "conversation.item.created":
        console.log("[å¯¹è¯é¡¹åˆ›å»º]", data.item?.type);
        break;

      case "error":
        console.error("[é”™è¯¯]", data.error);
        if (data.error?.message) {
          setError(data.error.message);
        }
        break;

      default:
        // å…¶ä»–æœªå¤„ç†çš„æ¶ˆæ¯ç±»å‹ä¹Ÿæ‰“å°å‡ºæ¥
        console.log("[å…¶ä»–æ¶ˆæ¯]", data.type);
    }
  };

  // ç»“æŸé¢è¯•
  const endInterview = useCallback(() => {
    setStatus("ending");

    // åœæ­¢å½•éŸ³
    if (recorderRef.current) {
      recorderRef.current.stop();
      recorderRef.current = null;
    }
    setIsRecording(false);

    // åœæ­¢è®¡æ—¶å™¨
    if (timerRef.current) {
      clearInterval(timerRef.current);
    }

    // å…³é—­ WebSocket
    if (wsRef.current) {
      wsRef.current.close();
      wsRef.current = null;
    }

    // å…³é—­éŸ³é¢‘æ’­æ”¾å™¨
    if (playerRef.current) {
      playerRef.current.close();
      playerRef.current = null;
    }

    // è·³è½¬åˆ°ç»“æœé¡µ
    const resultData = {
      messages,
      settings,
    };
    const encoded = encodeURIComponent(JSON.stringify(resultData));
    router.push(`/result?data=${encoded}`);
  }, [messages, settings, router]);

  // è·å–æ ‡é¢˜
  const getTitle = () => {
    if (!settings) return "é¢è¯•è¿›è¡Œä¸­";

    const modeNames: Record<string, string> = {
      civil: "å…¬åŠ¡å‘˜é¢è¯•",
      behavioral: "è¡Œä¸ºé¢è¯•",
      internet: "äº’è”ç½‘é¢è¯•",
      resume: "ç®€å†é¢è¯•",
      tech: "æŠ€æœ¯é¢è¯•",
    };

    const parts = [];
    if (settings.company) parts.push(settings.company);
    if (settings.position) parts.push(settings.position);
    if (settings.mode && !settings.company && !settings.position) {
      parts.push(modeNames[settings.mode] || "æ¨¡æ‹Ÿé¢è¯•");
    }

    if (settings.round) {
      const roundNames: Record<string, string> = {
        hr: "HRé¢",
        business: "ä¸šåŠ¡é¢",
        pressure: "å‹åŠ›é¢",
        final: "ç»ˆé¢",
      };
      parts.push(roundNames[settings.round] || "");
    }

    return parts.join(" Â· ") || "é¢è¯•è¿›è¡Œä¸­";
  };

  if (!settings) {
    return (
      <div className="min-h-screen flex items-center justify-center bg-background">
        <div className="text-center">
          <div className="w-8 h-8 border-2 border-primary border-t-transparent rounded-full animate-spin mx-auto mb-4" />
          <p className="text-muted-foreground">åŠ è½½ä¸­...</p>
        </div>
      </div>
    );
  }

  return (
    <main className="min-h-screen flex flex-col bg-background">
      {/* é¡¶éƒ¨æ  */}
      <div className="border-b border-border/50 bg-card/50 backdrop-blur-md px-4 py-3 flex items-center justify-between">
        <div className="flex items-center gap-3">
          <div className="w-2 h-2 rounded-full bg-green-500 animate-pulse" />
          <div className="text-sm text-foreground font-medium">{getTitle()}</div>
        </div>
        <div className="flex items-center gap-4">
          <div className="text-2xl font-mono text-primary font-bold">
            {formatTime(remainingTime)}
          </div>
        </div>
      </div>

      {/* å¯¹è¯åŒºåŸŸ */}
      <div className="flex-1 overflow-y-auto px-4 py-6">
        <div className="max-w-2xl mx-auto space-y-4">
          {messages.length === 0 && status === "active" && (
            <div className="text-center py-12">
              <div className="w-16 h-16 rounded-full bg-primary/10 flex items-center justify-center mx-auto mb-4">
                <div className="flex gap-1">
                  {[...Array(5)].map((_, i) => (
                    <div
                      key={i}
                      className="w-1 bg-primary rounded-full wave-bar"
                      style={{ animationDelay: `${i * 0.1}s` }}
                    />
                  ))}
                </div>
              </div>
              <p className="text-muted-foreground">é¢è¯•å®˜æ­£åœ¨å‡†å¤‡é—®é¢˜...</p>
            </div>
          )}

          {messages.map((msg) => (
            <div
              key={msg.id}
              className={`flex ${msg.role === "user" ? "justify-end" : "justify-start"} items-start gap-3`}
            >
              {/* AIå¤´åƒ */}
              {msg.role === "assistant" && (
                <div className="flex-shrink-0 relative">
                  <div className="absolute inset-0 w-10 h-10 rounded-full bg-blue-500/20 scale-150" />
                  <div className="absolute inset-0 w-10 h-10 rounded-full bg-blue-500/10 scale-[1.8]" />
                  <div className="relative w-10 h-10 rounded-full bg-gradient-to-br from-blue-500 to-cyan-400 flex items-center justify-center shadow-lg">
                    <div className="flex items-center justify-center gap-[2px]">
                      {[...Array(5)].map((_, i) => (
                        <div
                          key={i}
                          className="w-[2px] bg-white rounded-full"
                          style={{
                            height: i === 2 ? '14px' : i === 1 || i === 3 ? '10px' : '6px',
                          }}
                        />
                      ))}
                    </div>
                  </div>
                </div>
              )}
              <div
                className={`max-w-[75%] px-4 py-3 rounded-2xl text-sm ${
                  msg.role === "user"
                    ? "bg-primary text-primary-foreground rounded-br-md"
                    : "bg-card border border-border rounded-bl-md"
                }`}
              >
                {msg.content}
              </div>
            </div>
          ))}

          {/* AI æ­£åœ¨è¯´è¯æˆ–æ‰“å­—ä¸­ */}
          {(isAISpeaking || isTyping) && (
            <div className="flex justify-start items-start gap-3">
              {/* AIå¤´åƒå¸¦å£°æ³¢åŠ¨ç”» */}
              <div className="flex-shrink-0 relative">
                <div className={`absolute inset-0 w-10 h-10 rounded-full bg-blue-500/20 scale-150 ${isAISpeaking ? 'animate-pulse' : ''}`} />
                <div className={`absolute inset-0 w-10 h-10 rounded-full bg-blue-500/10 scale-[1.8] ${isAISpeaking ? 'animate-pulse' : ''}`} />
                <div className="relative w-10 h-10 rounded-full bg-gradient-to-br from-blue-500 to-cyan-400 flex items-center justify-center shadow-lg shadow-blue-500/30">
                  <div className="flex items-center justify-center gap-[2px]">
                    {[...Array(5)].map((_, i) => (
                      <div
                        key={i}
                        className="w-[2px] bg-white rounded-full transition-all duration-150"
                        style={{
                          height: isAISpeaking
                            ? `${6 + Math.random() * 10}px`
                            : i === 2 ? '14px' : i === 1 || i === 3 ? '10px' : '6px',
                          animation: isAISpeaking ? `soundwave 0.4s ease-in-out infinite` : 'none',
                          animationDelay: `${i * 0.08}s`,
                        }}
                      />
                    ))}
                  </div>
                </div>
              </div>
              <div className="max-w-[75%] px-4 py-3 rounded-2xl rounded-bl-md text-sm bg-card border border-border">
                {isTyping && displayedText ? (
                  <>
                    {displayedText}
                    <span className="animate-pulse ml-0.5">|</span>
                  </>
                ) : (
                  <span className="text-muted-foreground">æ­£åœ¨æ€è€ƒ...</span>
                )}
              </div>
            </div>
          )}

          <div ref={messagesEndRef} />
        </div>
      </div>

      {/* åº•éƒ¨æ§åˆ¶åŒº */}
      <div className="border-t border-border/50 bg-card/50 backdrop-blur-md px-4 py-6">
        {error && (
          <div className="max-w-2xl mx-auto mb-4">
            <div className="text-center text-destructive text-sm bg-destructive/10 rounded-lg py-2 px-4">
              {error}
            </div>
          </div>
        )}

        <div className="max-w-2xl mx-auto">
          {status === "idle" && (
            <Button
              onClick={connectWebSocket}
              className="w-full btn-gradient py-6 text-lg rounded-xl"
            >
              å¼€å§‹é¢è¯•
            </Button>
          )}

          {status === "connecting" && (
            <div className="text-center">
              <div className="w-8 h-8 border-2 border-primary border-t-transparent rounded-full animate-spin mx-auto mb-2" />
              <p className="text-muted-foreground">æ­£åœ¨è¿æ¥é¢è¯•å®˜...</p>
            </div>
          )}

          {status === "active" && (
            <div className="flex flex-col items-center gap-6">
              {/* çŠ¶æ€æç¤º */}
              {isAISpeaking && (
                <div className="flex items-center gap-2 px-4 py-2 rounded-full bg-primary/20 text-primary">
                  <div className="flex gap-0.5">
                    {[...Array(4)].map((_, i) => (
                      <div
                        key={i}
                        className="w-1 bg-primary rounded-full wave-bar"
                        style={{ animationDelay: `${i * 0.1}s` }}
                      />
                    ))}
                  </div>
                  <span className="text-sm">é¢è¯•å®˜æ­£åœ¨è¯´è¯...</span>
                </div>
              )}

              {/* å½•éŸ³æ§åˆ¶æŒ‰é’® */}
              <div className="flex items-center gap-4">
                {!isRecording ? (
                  <Button
                    onClick={startRecording}
                    disabled={isAISpeaking}
                    className="px-8 py-6 text-lg rounded-xl btn-gradient disabled:opacity-50"
                  >
                    {isAISpeaking ? "â³ ç­‰å¾…é¢è¯•å®˜è¯´å®Œ..." : "ğŸ¤ ç‚¹å‡»å¼€å§‹å›ç­”"}
                  </Button>
                ) : (
                  <Button
                    onClick={stopRecording}
                    className="px-8 py-6 text-lg rounded-xl bg-green-600 hover:bg-green-700 text-white animate-pulse"
                  >
                    âœ… å›ç­”å®Œæ¯•
                  </Button>
                )}
              </div>

              {isRecording && (
                <div className="flex items-center gap-2 text-green-500">
                  <div className="w-3 h-3 rounded-full bg-green-500 animate-pulse" />
                  <span className="text-sm">æ­£åœ¨å½•éŸ³... è¯´å®Œè¯·ç‚¹å‡»"å›ç­”å®Œæ¯•"</span>
                </div>
              )}

              {!isRecording && !isAISpeaking && (
                <div className="flex items-center gap-2 text-muted-foreground">
                  <span className="text-sm">AIè¯´å®Œåä¼šè‡ªåŠ¨å¼€å§‹å½•éŸ³ï¼Œä½ ä¹Ÿå¯ä»¥æ‰‹åŠ¨ç‚¹å‡»å¼€å§‹</span>
                </div>
              )}

              {/* ç»“æŸé¢è¯•æŒ‰é’® */}
              <Button
                variant="outline"
                onClick={endInterview}
                className="px-6 py-2 text-destructive border-destructive/50 hover:bg-destructive hover:text-destructive-foreground rounded-xl"
              >
                ç»“æŸé¢è¯•
              </Button>
            </div>
          )}

          {status === "ending" && (
            <div className="text-center">
              <div className="w-8 h-8 border-2 border-primary border-t-transparent rounded-full animate-spin mx-auto mb-2" />
              <p className="text-muted-foreground">æ­£åœ¨ç”Ÿæˆé¢è¯•æŠ¥å‘Š...</p>
            </div>
          )}
        </div>
      </div>
    </main>
  );
}

export default function InterviewPage() {
  return (
    <Suspense fallback={
      <div className="min-h-screen flex items-center justify-center bg-background">
        <div className="text-center">
          <div className="w-8 h-8 border-2 border-primary border-t-transparent rounded-full animate-spin mx-auto mb-4" />
          <p className="text-muted-foreground">åŠ è½½ä¸­...</p>
        </div>
      </div>
    }>
      <InterviewContent />
    </Suspense>
  );
}
