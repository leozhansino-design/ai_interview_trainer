"use client";

import { useRouter, useSearchParams } from "next/navigation";
import { useState, useEffect, useRef, useCallback, Suspense } from "react";
import { Button } from "@/components/ui/button";
import { AudioRecorder, AudioPlayer, encodeAudioToBase64 } from "@/lib/audio";
import { generateInterviewPrompt } from "@/lib/prompts";
import { INTERVIEWER_STYLES } from "@/lib/config";
import type { InterviewSettings, Message } from "@/types";

function InterviewContent() {
  const router = useRouter();
  const searchParams = useSearchParams();

  const [settings, setSettings] = useState<InterviewSettings | null>(null);
  const [status, setStatus] = useState<"idle" | "connecting" | "active" | "ending">("idle");
  const [messages, setMessages] = useState<Message[]>([]);
  const [currentTranscript, setCurrentTranscript] = useState("");
  const [remainingTime, setRemainingTime] = useState(0);
  const [isRecording, setIsRecording] = useState(false);
  const [isAISpeaking, setIsAISpeaking] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const wsRef = useRef<WebSocket | null>(null);
  const recorderRef = useRef<AudioRecorder | null>(null);
  const playerRef = useRef<AudioPlayer | null>(null);
  const timerRef = useRef<NodeJS.Timeout | null>(null);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  // è§£æè®¾ç½®
  useEffect(() => {
    const settingsParam = searchParams.get("settings");
    if (settingsParam) {
      try {
        const parsed = JSON.parse(decodeURIComponent(settingsParam));
        setSettings(parsed);
        setRemainingTime(parsed.duration * 60);
      } catch {
        setError("æ— æ•ˆçš„é¢è¯•è®¾ç½®");
      }
    }
  }, [searchParams]);

  // æ»šåŠ¨åˆ°æœ€æ–°æ¶ˆæ¯
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  }, [messages, currentTranscript]);

  // å€’è®¡æ—¶
  useEffect(() => {
    if (status === "active" && remainingTime > 0) {
      timerRef.current = setInterval(() => {
        setRemainingTime((prev) => {
          if (prev <= 1) {
            endInterview();
            return 0;
          }
          return prev - 1;
        });
      }, 1000);
    }

    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
    };
  }, [status]);

  // æ ¼å¼åŒ–æ—¶é—´
  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, "0")}:${secs.toString().padStart(2, "0")}`;
  };

  // æ‰‹åŠ¨å¼€å§‹å½•éŸ³
  const startRecording = useCallback(async () => {
    if (isRecording || !wsRef.current || isAISpeaking) return;

    try {
      const recorder = new AudioRecorder();
      recorderRef.current = recorder;

      await recorder.start((audioData) => {
        if (wsRef.current?.readyState === WebSocket.OPEN) {
          const base64Audio = encodeAudioToBase64(audioData);
          wsRef.current.send(
            JSON.stringify({
              type: "input_audio_buffer.append",
              audio: base64Audio,
            })
          );
        }
      });

      setIsRecording(true);
    } catch (err) {
      console.error("Failed to start recording:", err);
      setError("æ— æ³•å¯åŠ¨éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™");
    }
  }, [isRecording, isAISpeaking]);

  // æ‰‹åŠ¨åœæ­¢å½•éŸ³å¹¶æäº¤
  const stopRecording = useCallback(() => {
    if (!isRecording || !wsRef.current) return;

    // åœæ­¢å½•éŸ³
    if (recorderRef.current) {
      recorderRef.current.stop();
      recorderRef.current = null;
    }
    setIsRecording(false);

    // æäº¤éŸ³é¢‘ç¼“å†²åŒº
    wsRef.current.send(JSON.stringify({
      type: "input_audio_buffer.commit",
    }));

    // è§¦å‘ AI å›å¤
    wsRef.current.send(JSON.stringify({
      type: "response.create",
      response: {
        modalities: ["audio", "text"],
      },
    }));
  }, [isRecording]);

  // è¿æ¥ WebSocket
  const connectWebSocket = useCallback(async () => {
    if (!settings) return;

    setStatus("connecting");
    setError(null);

    try {
      // åˆå§‹åŒ–éŸ³é¢‘æ’­æ”¾å™¨
      playerRef.current = new AudioPlayer();

      // è¿æ¥ WebSocket ä»£ç†
      const wsUrl = process.env.NEXT_PUBLIC_WS_PROXY_URL || "ws://localhost:8768";
      const ws = new WebSocket(wsUrl);
      wsRef.current = ws;

      ws.onopen = () => {
        console.log("WebSocket connected");

        // å‘é€ session.update - ä½¿ç”¨ Server VAD è‡ªåŠ¨æ£€æµ‹è¯­éŸ³
        const prompt = generateInterviewPrompt({
          mode: settings.mode,
          position: settings.position,
          company: settings.company,
          round: settings.round as any,
          category: settings.category,
          techStack: (settings as any).techStack,
          resumeContent: settings.resumeContent,
          duration: settings.duration,
        });

        const voice = settings.round
          ? INTERVIEWER_STYLES[settings.round]?.voice || "ash"
          : "ash";

        const sessionUpdate = {
          type: "session.update",
          session: {
            modalities: ["audio", "text"],
            instructions: prompt,
            voice: voice,
            input_audio_format: "pcm16",
            output_audio_format: "pcm16",
            input_audio_transcription: { model: "whisper-1" },
            turn_detection: null, // æ‰‹åŠ¨æ¨¡å¼ï¼Œä¸ä½¿ç”¨è‡ªåŠ¨è¯­éŸ³æ£€æµ‹
          },
        };

        ws.send(JSON.stringify(sessionUpdate));

        // è§¦å‘ AI å¼€åœºç™½
        setTimeout(() => {
          ws.send(JSON.stringify({
            type: "response.create",
            response: {
              modalities: ["audio", "text"],
            },
          }));
        }, 500);

        setStatus("active");
      };

      ws.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data);
          handleServerMessage(data);
        } catch (e) {
          console.error("Failed to parse message:", e);
        }
      };

      ws.onerror = (event) => {
        console.error("WebSocket error:", event);
        setError("è¿æ¥å‡ºé”™ï¼Œè¯·åˆ·æ–°é‡è¯•");
        setStatus("idle");
      };

      ws.onclose = () => {
        console.log("WebSocket closed");
        if (status === "active") {
          setStatus("ending");
        }
      };
    } catch (err) {
      console.error("Connection failed:", err);
      setError("è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ");
      setStatus("idle");
    }
  }, [settings]);

  // å¤„ç†æœåŠ¡å™¨æ¶ˆæ¯
  const handleServerMessage = (data: any) => {
    switch (data.type) {
      case "session.created":
      case "session.updated":
        console.log("Session ready");
        break;

      case "response.audio.delta":
        // AI æ­£åœ¨è¯´è¯
        setIsAISpeaking(true);
        if (data.delta && playerRef.current) {
          playerRef.current.play(data.delta);
        }
        break;

      case "response.audio_transcript.delta":
        setCurrentTranscript((prev) => prev + (data.delta || ""));
        break;

      case "response.audio_transcript.done":
        // AI è¯´å®Œä¸€å¥è¯
        if (data.transcript) {
          const newMessage: Message = {
            id: Date.now().toString(),
            role: "assistant",
            content: data.transcript,
            timestamp: Date.now(),
          };
          setMessages((prev) => [...prev, newMessage]);
          setCurrentTranscript("");
        }
        break;

      case "response.done":
        // AI å®Œå…¨è¯´å®Œï¼Œå¯ä»¥å¼€å§‹å½•éŸ³
        setIsAISpeaking(false);
        break;

      case "conversation.item.input_audio_transcription.completed":
        // ç”¨æˆ·è¯´å®Œè¯ï¼Œè½¬å½•å®Œæˆ
        if (data.transcript) {
          const newMessage: Message = {
            id: Date.now().toString(),
            role: "user",
            content: data.transcript,
            timestamp: Date.now(),
          };
          setMessages((prev) => [...prev, newMessage]);
        }
        break;

      case "error":
        console.error("Server error:", data.error);
        if (data.error?.message) {
          setError(data.error.message);
        }
        break;
    }
  };

  // ç»“æŸé¢è¯•
  const endInterview = useCallback(() => {
    setStatus("ending");

    // åœæ­¢å½•éŸ³
    if (recorderRef.current) {
      recorderRef.current.stop();
      recorderRef.current = null;
    }
    setIsRecording(false);

    // åœæ­¢è®¡æ—¶å™¨
    if (timerRef.current) {
      clearInterval(timerRef.current);
    }

    // å…³é—­ WebSocket
    if (wsRef.current) {
      wsRef.current.close();
      wsRef.current = null;
    }

    // å…³é—­éŸ³é¢‘æ’­æ”¾å™¨
    if (playerRef.current) {
      playerRef.current.close();
      playerRef.current = null;
    }

    // è·³è½¬åˆ°ç»“æœé¡µ
    const resultData = {
      messages,
      settings,
    };
    const encoded = encodeURIComponent(JSON.stringify(resultData));
    router.push(`/result?data=${encoded}`);
  }, [messages, settings, router]);

  // è·å–æ ‡é¢˜
  const getTitle = () => {
    if (!settings) return "é¢è¯•è¿›è¡Œä¸­";

    const modeNames: Record<string, string> = {
      civil: "å…¬åŠ¡å‘˜é¢è¯•",
      behavioral: "è¡Œä¸ºé¢è¯•",
      internet: "äº’è”ç½‘é¢è¯•",
      resume: "ç®€å†é¢è¯•",
      tech: "æŠ€æœ¯é¢è¯•",
    };

    const parts = [];
    if (settings.company) parts.push(settings.company);
    if (settings.position) parts.push(settings.position);
    if (settings.mode && !settings.company && !settings.position) {
      parts.push(modeNames[settings.mode] || "æ¨¡æ‹Ÿé¢è¯•");
    }

    if (settings.round) {
      const roundNames: Record<string, string> = {
        hr: "HRé¢",
        business: "ä¸šåŠ¡é¢",
        pressure: "å‹åŠ›é¢",
        final: "ç»ˆé¢",
      };
      parts.push(roundNames[settings.round] || "");
    }

    return parts.join(" Â· ") || "é¢è¯•è¿›è¡Œä¸­";
  };

  if (!settings) {
    return (
      <div className="min-h-screen flex items-center justify-center bg-background">
        <div className="text-center">
          <div className="w-8 h-8 border-2 border-primary border-t-transparent rounded-full animate-spin mx-auto mb-4" />
          <p className="text-muted-foreground">åŠ è½½ä¸­...</p>
        </div>
      </div>
    );
  }

  return (
    <main className="min-h-screen flex flex-col bg-background">
      {/* é¡¶éƒ¨æ  */}
      <div className="border-b border-border/50 bg-card/50 backdrop-blur-md px-4 py-3 flex items-center justify-between">
        <div className="flex items-center gap-3">
          <div className="w-2 h-2 rounded-full bg-green-500 animate-pulse" />
          <div className="text-sm text-foreground font-medium">{getTitle()}</div>
        </div>
        <div className="flex items-center gap-4">
          <div className="text-2xl font-mono text-primary font-bold">
            {formatTime(remainingTime)}
          </div>
        </div>
      </div>

      {/* å¯¹è¯åŒºåŸŸ */}
      <div className="flex-1 overflow-y-auto px-4 py-6">
        <div className="max-w-2xl mx-auto space-y-4">
          {messages.length === 0 && status === "active" && (
            <div className="text-center py-12">
              <div className="w-16 h-16 rounded-full bg-primary/10 flex items-center justify-center mx-auto mb-4">
                <div className="flex gap-1">
                  {[...Array(5)].map((_, i) => (
                    <div
                      key={i}
                      className="w-1 bg-primary rounded-full wave-bar"
                      style={{ animationDelay: `${i * 0.1}s` }}
                    />
                  ))}
                </div>
              </div>
              <p className="text-muted-foreground">é¢è¯•å®˜æ­£åœ¨å‡†å¤‡é—®é¢˜...</p>
            </div>
          )}

          {messages.map((msg) => (
            <div
              key={msg.id}
              className={`flex ${msg.role === "user" ? "justify-end" : "justify-start"}`}
            >
              <div
                className={`max-w-[80%] px-4 py-3 rounded-2xl text-sm ${
                  msg.role === "user"
                    ? "bg-primary text-primary-foreground rounded-br-md"
                    : "bg-card border border-border rounded-bl-md"
                }`}
              >
                {msg.content}
              </div>
            </div>
          ))}

          {/* AI æ­£åœ¨è¯´çš„å†…å®¹ */}
          {currentTranscript && (
            <div className="flex justify-start">
              <div className="max-w-[80%] px-4 py-3 rounded-2xl rounded-bl-md text-sm bg-card border border-border">
                {currentTranscript}
                <span className="inline-block w-2 h-4 bg-primary ml-1 animate-pulse" />
              </div>
            </div>
          )}

          <div ref={messagesEndRef} />
        </div>
      </div>

      {/* åº•éƒ¨æ§åˆ¶åŒº */}
      <div className="border-t border-border/50 bg-card/50 backdrop-blur-md px-4 py-6">
        {error && (
          <div className="max-w-2xl mx-auto mb-4">
            <div className="text-center text-destructive text-sm bg-destructive/10 rounded-lg py-2 px-4">
              {error}
            </div>
          </div>
        )}

        <div className="max-w-2xl mx-auto">
          {status === "idle" && (
            <Button
              onClick={connectWebSocket}
              className="w-full btn-gradient py-6 text-lg rounded-xl"
            >
              å¼€å§‹é¢è¯•
            </Button>
          )}

          {status === "connecting" && (
            <div className="text-center">
              <div className="w-8 h-8 border-2 border-primary border-t-transparent rounded-full animate-spin mx-auto mb-2" />
              <p className="text-muted-foreground">æ­£åœ¨è¿æ¥é¢è¯•å®˜...</p>
            </div>
          )}

          {status === "active" && (
            <div className="flex flex-col items-center gap-6">
              {/* çŠ¶æ€æç¤º */}
              {isAISpeaking && (
                <div className="flex items-center gap-2 px-4 py-2 rounded-full bg-primary/20 text-primary">
                  <div className="flex gap-0.5">
                    {[...Array(4)].map((_, i) => (
                      <div
                        key={i}
                        className="w-1 bg-primary rounded-full wave-bar"
                        style={{ animationDelay: `${i * 0.1}s` }}
                      />
                    ))}
                  </div>
                  <span className="text-sm">é¢è¯•å®˜æ­£åœ¨è¯´è¯...</span>
                </div>
              )}

              {/* å½•éŸ³æ§åˆ¶æŒ‰é’® */}
              <div className="flex items-center gap-4">
                {!isRecording ? (
                  <Button
                    onClick={startRecording}
                    disabled={isAISpeaking}
                    className="px-8 py-6 text-lg rounded-xl btn-gradient disabled:opacity-50"
                  >
                    ğŸ¤ ç‚¹å‡»å¼€å§‹å›ç­”
                  </Button>
                ) : (
                  <Button
                    onClick={stopRecording}
                    className="px-8 py-6 text-lg rounded-xl bg-green-600 hover:bg-green-700 text-white animate-pulse"
                  >
                    â¹ï¸ ç‚¹å‡»ç»“æŸå›ç­”
                  </Button>
                )}
              </div>

              {isRecording && (
                <div className="flex items-center gap-2 text-green-500">
                  <div className="w-3 h-3 rounded-full bg-green-500 animate-pulse" />
                  <span className="text-sm">æ­£åœ¨å½•éŸ³ä¸­ï¼Œè¯´å®Œè¯·ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®</span>
                </div>
              )}

              {/* ç»“æŸé¢è¯•æŒ‰é’® */}
              <Button
                variant="outline"
                onClick={endInterview}
                className="px-6 py-2 text-destructive border-destructive/50 hover:bg-destructive hover:text-destructive-foreground rounded-xl"
              >
                ç»“æŸé¢è¯•
              </Button>

              <p className="text-muted-foreground text-xs text-center">
                ç‚¹å‡»"å¼€å§‹å›ç­”"åè¯´è¯ï¼Œè¯´å®Œç‚¹å‡»"ç»“æŸå›ç­”"
              </p>
            </div>
          )}

          {status === "ending" && (
            <div className="text-center">
              <div className="w-8 h-8 border-2 border-primary border-t-transparent rounded-full animate-spin mx-auto mb-2" />
              <p className="text-muted-foreground">æ­£åœ¨ç”Ÿæˆé¢è¯•æŠ¥å‘Š...</p>
            </div>
          )}
        </div>
      </div>
    </main>
  );
}

export default function InterviewPage() {
  return (
    <Suspense fallback={
      <div className="min-h-screen flex items-center justify-center bg-background">
        <div className="text-center">
          <div className="w-8 h-8 border-2 border-primary border-t-transparent rounded-full animate-spin mx-auto mb-4" />
          <p className="text-muted-foreground">åŠ è½½ä¸­...</p>
        </div>
      </div>
    }>
      <InterviewContent />
    </Suspense>
  );
}
